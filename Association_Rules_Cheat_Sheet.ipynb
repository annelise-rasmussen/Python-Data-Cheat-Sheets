{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e344da",
   "metadata": {
    "id": "23e344da"
   },
   "source": [
    "# Association Rules Cheat Sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e039e2df",
   "metadata": {
    "id": "e039e2df"
   },
   "source": [
    "## Convert transactional data to dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d4ec4",
   "metadata": {
    "id": "8a2d4ec4"
   },
   "outputs": [],
   "source": [
    "data = list(df[\"Column_Name\"].apply(lambda X:x.split(\",\"))) #splits values within `Column_Name` to a list, based on \",\"\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder #import transactionencoder function from mlxtend\n",
    "a = TranactionEncoder() #save function in object called 'a'\n",
    "a_data = a.fit(data).transform(data) #create new data object that transforms list to dummy variables for each item\n",
    "df = pd.DataFrame(a_data,columns=a.columns_) #create new dataframe object from the dummy variables, take column names\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3993df",
   "metadata": {
    "id": "0d3993df"
   },
   "source": [
    "### Replace True/False Values with 1 and 0s using dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b887d",
   "metadata": {
    "id": "e32b887d"
   },
   "outputs": [],
   "source": [
    "df.replace({True: 1, False: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205afef0",
   "metadata": {
    "id": "205afef0"
   },
   "source": [
    "### If any columns are duplicated, make sure to trim whitespace then drop duplicated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cf4ca",
   "metadata": {
    "id": "cb8cf4ca"
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '') #trim leading and trailing whitespace from column names\n",
    "df = df.loc[:, ~df.columns.duplicated()] #drop duplicated columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f1d0ff",
   "metadata": {
    "id": "a2f1d0ff"
   },
   "source": [
    "## Apply Apriori Function to Generate Frequent Rulesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277da120",
   "metadata": {
    "id": "277da120"
   },
   "outputs": [],
   "source": [
    "freq_is = aprior(df, min_support = 0.2, use_colnames = True, verbose = 1) #change the minimum support value\n",
    "freq_is #show the frequent itemsets table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964980b0",
   "metadata": {
    "id": "964980b0"
   },
   "source": [
    "## Run Association Rules Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0820ae",
   "metadata": {
    "id": "ee0820ae"
   },
   "outputs": [],
   "source": [
    "df_ar = association_rules(freq_is, metric = \"confidence\", min_threshold = 0.6) #change minimum_threshold confidence value\n",
    "df_ar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b14b55",
   "metadata": {
    "id": "c5b14b55"
   },
   "source": [
    "## Calculate support count, support, confidence and lift by formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c3dfb",
   "metadata": {
    "id": "0a5c3dfb"
   },
   "outputs": [],
   "source": [
    "sc = df['Column_name'].sum() #calculate support count of itemset containing one item\n",
    "sc = len(df[(df['Col_1'] == 1) &  (df['Col_3'] == 1)]) #calculate support count of itemset containing 2 items\n",
    "\n",
    "support = sc/len(df) #divide the support count by the total number of observations in df\n",
    "support #show support value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fca4f4",
   "metadata": {
    "id": "f5fca4f4"
   },
   "outputs": [],
   "source": [
    "sc_x = len(df[(df['Col_1'] == 1) & (df['Col_2'] == 1)]) #support count of antecedent with two items in itemset\n",
    "sc_xy = len(df[(df['Col_1'] == 1) & (df['Col_2'] == 1) & df['Col_3'] == 1]) #support count of antecendent and consequent\n",
    "\n",
    "confidence = sc_xy/sc_x #divide support count of antecendent and consequent by the support count of the antecedent\n",
    "confidence #show confidence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae03f94",
   "metadata": {
    "id": "9ae03f94"
   },
   "outputs": [],
   "source": [
    "sc_y = df['Col_1'].sum() #support count of consequent with itemset with one item\n",
    "s_y = sc_y/len(df) #support of consequent\n",
    "\n",
    "sc_x = len(df[(df['Col_2'] == 1) & (df['Col_3'] == 1)]) #support count of antecedent with two items\n",
    "sc_xy = len(df[(df['Col_2'] == 1) & (df['Col_3'] == 1) & (df['Col_3'] == 1)]) #calculate support count of ante/cons\n",
    "\n",
    "confidence = sc_xy/sc_x #confidence of x --> y\n",
    "Lift = confidence/s_y #lift of x --> y"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
